#  Self-Healing Machine Learning System

### Drift-Aware, Auto-Retraining, Production-Grade MLOps Architecture

> **A continuously running ML system that monitors itself, detects data drift from live traffic, retrains automatically, and serves predictions without downtime.**

This repository represents a **real-world ML production system**, not a demo or academic project.
It is designed to stay alive **24/7**, recover from failures, and evolve as data changes.

---

##  What Makes This Project Different

Most ML projects stop at:

* Training a model once
* Exposing a prediction API
* Calling it â€œproductionâ€

This system goes **much further**:

- Runs continuously on cloud infrastructure
- Detects data drift from real inference traffic
- Automatically retrains when drift is confirmed
- Registers new model versions without manual steps
- Survives server reboot & container restart
- Exposes full observability (metrics, latency, health)

This is how **real ML systems** work in production environments.

---

##  System Architecture (Conceptual)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client     â”‚
â”‚ (REST Call)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FastAPI Inference Server â”‚
â”‚  â€¢ Feature Builder       â”‚
â”‚  â€¢ MLflow Model          â”‚
â”‚  â€¢ Prediction Logger     â”‚
â”‚  â€¢ Prometheus Metrics    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Live Prediction Logs     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Drift Detection Engine   â”‚
â”‚  â€¢ Statistical Analysis  â”‚
â”‚  â€¢ Drift Report          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Auto Retraining Pipeline â”‚
â”‚  â€¢ Triggered by Drift    â”‚
â”‚  â€¢ MLflow Tracking       â”‚
â”‚  â€¢ Model Versioning      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Updated Model Artifact   â”‚
â”‚ Used by Inference API    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

##  Core Design Principles

### 1ï¸ Deterministic Inference

* Feature order is locked using a template
* No silent column mismatch
* No runtime surprises

### 2ï¸ Drift-First Thinking

* Drift is treated as a **first-class signal**
* Model accuracy degradation is not ignored

### 3ï¸ Automation Over Manual Ops

* Retraining does **not** require a human
* Decisions are driven by data, not schedules

### 4ï¸ Observability by Default

* Every request is measured
* Every prediction is logged
* Every failure is visible

---

##  Technology Stack (Why These Choices)

| Component      | Tool       | Reason                        |
| -------------- | ---------- | ----------------------------- |
| API            | FastAPI    | Async, fast, production-ready |
| Model Registry | MLflow     | Versioning & lineage          |
| Deployment     | Docker     | Reproducibility               |
| Monitoring     | Prometheus | Industry standard             |
| Dashboards     | Grafana    | Real-time observability       |
| Scheduling     | Cron (EC2) | Simple & reliable             |
| Cloud          | AWS EC2    | Full control, low cost        |

No vendor lock-in. No magic services.

---

## ðŸ“ Repository Structure (Intentional, Not Random)

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ serving/            # Inference API
â”‚   â”œâ”€â”€ monitoring/         # Drift & metrics logic
â”‚   â”œâ”€â”€ retraining/         # Auto retrain orchestration
â”‚   â””â”€â”€ training/           # Model training pipeline
â”‚
â”œâ”€â”€ exported_model/         # MLflow model artifact
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/          # Feature templates
â”‚   â””â”€â”€ monitoring/         # Drift reports
â”‚
â”œâ”€â”€ docker/                 # Docker configuration
â”œâ”€â”€ scripts/                # Automation scripts
â”œâ”€â”€ monitoring/             # Prometheus configs
â””â”€â”€ README.md
```

Every directory exists for a reason.

---

##  API Endpoints

### Health Check

```
GET /health
```

Response:

```json
{
  "status": "ok",
  "model_loaded": true
}
```

Used by:

* Load balancers
* Monitoring systems
* Deployment validation

---

### Prediction Endpoint

```
POST /predict
```

Request:

```json
{
  "date": "2024-01-10",
  "category": "Electronics",
  "region": "North",
  "price": 1000,
  "promo": 1
}
```

Response:

```json
{
  "predicted_sales": 34.92
}
```

---

### Metrics

```
GET /metrics
```

Exposed for Prometheus scraping.

---

##  Observability (Real, Not Fake)

Tracked metrics include:

* Request count by endpoint
* Request latency
* Prediction latency
* Error rates

Grafana dashboards visualize:

* Traffic patterns
* System health
* Model behavior over time

---

##  Self-Healing Logic (Step-by-Step)

1. API receives live traffic
2. Predictions are logged
3. Drift detection compares:

   * Training distribution
   * Live inference distribution
4. Drift report is generated
5. If drift exceeds threshold:

   * Retraining pipeline is triggered
6. New model is trained
7. Model is registered in MLflow
8. System continues serving predictions

No downtime. No manual retraining.

---

## Reliability Proof

* Survives EC2 reboot
* Survives Docker restart
* Model reloads correctly
* API continues serving traffic
* Retraining works post-deployment

This has been **validated in a live cloud environment**.

---

This project demonstrates:

* Real MLOps thinking
* Production debugging ability
* Cloud deployment experience
* Monitoring & observability
* Automated ML lifecycle design

This is **how ML engineers work**, not how students code.

---

##  Current Status

**Production-Ready**
**24/7 Cloud Deployed**
**Self-Healing Enabled**

---


##  Author Note

TALARI JAYAKIRAN
This system was built end-to-end with a **production mindset**:

> *If it breaks at 3 AM, itâ€™s not production.*
> *If services are provide to users in 24/7 then only that system is production.*


